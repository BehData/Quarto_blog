[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Proyectos",
    "section": "",
    "text": "Car crash and number of deathly victims: a peruvian case\n\n\n\n\n\n\n\nMultiple linear regression\n\n\nCar Crash\n\n\n\n\nNumber of vehicles involved in a car crash influence in the number of deathly victims?\n\n\n\n\n\n\nMar 12, 2023\n\n\nDaniel Calenzani\n\n\n\n\n\n\n  \n\n\n\n\nDeterminants of COVID-19 vaccination intention\n\n\n\n\n\n\n\nMultiple linear regression\n\n\nCOVID-19\n\n\n\n\nSearch the determinants of COVID-19 vaccination intention using multiple regression analysis\n\n\n\n\n\n\nMar 12, 2023\n\n\nElías Aburto\n\n\n\n\n\n\n  \n\n\n\n\nWorking Memory, Mathematical Anxiety\n\n\n\n\n\n\n\nMultiple linear regression\n\n\nMath Anxiety\n\n\n\n\nSearch the determinants of math performance\n\n\n\n\n\n\nMar 12, 2023\n\n\nJorge Huanca\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis is a dummy blog posts\n\n\n\n\n\n\n\n123\n\n\nSecond Tag\n\n\n\n\nThis is a test post. In this post, I try out different functionalities\n\n\n\n\n\n\nJun 1, 2022\n\n\nDefault\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "INICIATIVA CIENCIA DE DATOS",
    "section": "",
    "text": "Bienvenidos a esta iniciativa!\nEste grupo está conformado por profesionales de psicología y antropología, interesados en aprender métodos computacionales para incorporarlos a nuestros proyectos de investigación.\nTo get started, you can check out my most popular content below. You can find me on Twitter or GitHub and YouTube. Feel free to reach out to me via mail and subscribe to my email newsletter.\n\n\n\nData Visualization\n\nThis will be filled…\n…when everything i sdfs ready.f adf asd sdf sdf\nBla bla bla bla sdf s sd fs sdf sdfasdfsf\n\n\n\nStats/ML\n\nThis will be filled…\n…when everything is ready.\nBla bla bla bla\n\n\n\nDashboards\n\nThis will be filled…\n…when everything is ready.\nBla bla bla bla\n\n\n\nYouTube\n\nThis will be filled…\n…when everything is ready.\nBla bla bla bla"
  },
  {
    "objectID": "posts/new/new_post.html",
    "href": "posts/new/new_post.html",
    "title": "This is a dummy blog posts",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus.\n\n\nThis is inline code plus a small code chunk.\n\nlibrary(tidyverse)\n\nggplot(mpg) +\n  geom_jitter(aes(cty, hwy), size = 4, alpha = 0.5) \n\n\n\n\n\n\n\n\n\n\n\nTransforming OLS estimatesMaximizing likelihood\n\n\n\n\nCode\npreds_lm %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  theme_minimal(base_size = 12) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\nCode\nglm.mod <- glm(sex ~ body_mass_g + bill_length_mm + species, family = binomial, data = dat)\n\npreds <- dat %>% \n  mutate(\n    prob.fit = glm.mod$fitted.values,\n    prediction = if_else(prob.fit > 0.5, 'male', 'female'),\n    correct = if_else(sex == prediction, 'correct', 'incorrect')\n  )\n\n\npreds %>% \n  ggplot(aes(body_mass_g, bill_length_mm, col = correct)) +\n  geom_jitter(size = 4, alpha = 0.6) +\n  facet_wrap(vars(species)) +\n  scale_x_continuous(breaks = seq(3000, 6000, 1000)) +\n  scale_color_manual(values = c('grey60', thematic::okabe_ito(3)[3])) +\n  theme_minimal(base_size = 10) +\n  theme(\n    legend.position = 'top', \n    panel.background = element_rect(color = 'black'),\n    panel.grid.minor = element_blank()\n  ) +\n  labs(\n    x = 'Body mass (in g)',\n    y = 'Bill length (in mm)'\n  )\n\n\n\n\n\n\n\n\n\n\n\\[\n\\int_0^1 f(x) \\ dx\n\\]\n\n\n\n\n\n\n\n\ngeom_density(\n  mapping = NULL,\n  data = NULL,\n  stat = \"density\",\n  position = \"identity\",\n  ...,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE,\n  outline.type = \"upper\"\n)\n\n\nstat_density(\n  mapping = NULL,\n  data = NULL,\n  geom = \"area\",\n  position = \"stack\",\n  ...,\n  bw = \"nrd0\",\n  adjust = 1,\n  kernel = \"gaussian\",\n  n = 512,\n  trim = FALSE,\n  na.rm = FALSE,\n  orientation = NA,\n  show.legend = NA,\n  inherit.aes = TRUE\n)\n\n\n\n\n\n\n\nggplot(data = gapminder::gapminder, mapping = aes(x = lifeExp, fill = continent)) +\n  stat_density(position = \"identity\", alpha = 0.5)\n\n\n\n\nBla bla bla. This is a caption in the margin. Super cool isn’t it?"
  },
  {
    "objectID": "posts/new/regresion.html",
    "href": "posts/new/regresion.html",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "",
    "text": "Problem: What are the determinants of COVID-19 vaccination intention?\nObjective: To identify the determinants of COVID-19 vaccination through an application of the Theory of Planned Behavior.\nHypothesis: H1: Control beliefs have a direct impact on COVID-19 vaccination intention H2: Utility beliefs have a direct impact on COVID-19 vaccination intention H3: Social norm beliefs have a direct impact on COVID-19 vaccination intention\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Nam suscipit est nec dui eleifend, at dictum elit ullamcorper. Aliquam feugiat dictum bibendum. Praesent fermentum laoreet quam, cursus volutpat odio dapibus in. Fusce luctus porttitor vehicula. Donec ac tortor nisi. Donec at lectus tortor. Morbi tempor, nibh non euismod viverra, metus arcu aliquet elit, sed fringilla urna leo vel purus."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "",
    "text": "Original Research: Reactance and perceived disease severity as determinants of COVID-19 vaccination intention: An application of the theory of planned behavior\nAuthors: Dariusz Drążkowski, Radosław Trepanowski, Adam Mickiewicz\nYear: 2021\nSample: 551 Polish participants\nDOI: https://doi.org/10.1080/13548506.2021.2014060"
  },
  {
    "objectID": "posts/post-with-code/index.html#a.-model-evaluation",
    "href": "posts/post-with-code/index.html#a.-model-evaluation",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "A. Model Evaluation",
    "text": "A. Model Evaluation\n\nA1. Regression coeficients and r-square\nLoad the database\n\nMydata=read.spss(\"data/COVID_data.sav\",to.data.frame=T,use.value.labels=FALSE)\nsummary(Mydata$SE_Total)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   3.00   12.00   15.00   15.42   18.00   21.00 \n\n\nPerform the linear regression analysis\n\nIntention_lm <- lm(IN_Total ~ SN_Total + BC_Total + AT_Total, data = Mydata)\nsummary(Intention_lm)\n\n\nCall:\nlm(formula = IN_Total ~ SN_Total + BC_Total + AT_Total, data = Mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.4622  -1.2412   0.1199   1.3464  11.0907 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.71571    0.36855  -4.655 4.07e-06 ***\nSN_Total     0.36218    0.03976   9.109  < 2e-16 ***\nBC_Total     0.29052    0.03483   8.341 6.00e-16 ***\nAT_Total     0.45369    0.03504  12.946  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.457 on 547 degrees of freedom\nMultiple R-squared:  0.7865,    Adjusted R-squared:  0.7853 \nF-statistic: 671.5 on 3 and 547 DF,  p-value: < 2.2e-16\n\n\n\n\nA2. Interpretation\nBs ajusted:\nFor each point obtained in the scale of subjective norms, the intenton to COVID-19 vaccination intention will increase 0.36 points. Also, subjective norms had a direct effect on COVID-19 vaccination intention it was statistically significant.\nFor each point obtained in the scale of Behavioral Control, the intenton to COVID-19 vaccination intention will increase 0.29 points. Also, Behavioral Control had a direct effect on COVID-19 vaccination intention and it was statistically significant.\nFor each point obtained in the scale of Attitude Toward Covid-19 vaccination, the intenton to COVID-19 vaccination intention will increase 0.45 points. Also, Attitude Toward Covid-19 vaccination had a direct effect on COVID-19 vaccination intention and statistical significance.\nThe model with these three determinants explain 78% of variance of COVID-19 vaccination intention."
  },
  {
    "objectID": "posts/post-with-code/index.html#b.-regression-model-assumtions",
    "href": "posts/post-with-code/index.html#b.-regression-model-assumtions",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "B. Regression Model Assumtions",
    "text": "B. Regression Model Assumtions\n\nB1. Lineality between IVs and Dv\n\nplot(IN_Total ~ SN_Total, data = Mydata)\n\n\n\nplot(IN_Total ~ BC_Total, data = Mydata)\n\n\n\nplot(IN_Total ~ AT_Total, data = Mydata)\n\n\n\n\n\n\nB2. Independence of observations\nThe observation from our model are independent.\nThis was fulfilled when each observation was made by one participant.\n\n\nB3. Homocedasticity\nThe errors from our model have equal variance.\n\npar(mfrow=c(2,2))\nplot(Intention_lm)\n\n\n\npar(mfrow=c(1,1))\n\n\n\nB4. Normality of Errors\nThe errors from our model are normally distributed.\n\npar(mfrow=c(2,2))\nplot(Intention_lm)\n\n\n\npar(mfrow=c(1,1))\n\n\n\nB5. Multicollinality: evaluate if the IVs are redundant.\n\nvif(Intention_lm)\n\nSN_Total BC_Total AT_Total \n2.984366 1.899331 2.991759"
  },
  {
    "objectID": "posts/post-with-code/index.html#multiple-regression-analysis-step-by-step",
    "href": "posts/post-with-code/index.html#multiple-regression-analysis-step-by-step",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "Multiple Regression Analysis: Step by step",
    "text": "Multiple Regression Analysis: Step by step\nProblem: What are the determinants of COVID-19 vaccination intention?\nObjective: To identify the determinants of COVID-19 vaccination through an application of the Theory of Planned Behavior.\nHypothesis: H1: Control beliefs have a direct impact on COVID-19 vaccination intention H2: Utility beliefs have a direct impact on COVID-19 vaccination intention H3: Social norm beliefs have a direct impact on COVID-19 vaccination intention\nSteps to prove the hypothesis\nA. Model Evaluation\n\nRegression coeficients and r-square\nInterpretation\n\nB. Regression Model Assumtions\n\nLineality between IVs and Dv\nIndependence of observations: The observation from our model are independent.\nHomoscedasticity: The errors from our model have equal variance.\nNormality of Errors: The errors from our model are normally distributed.\nMulticollinality: evaluate if the IVs are redundant.\n\n\nLoad the packages\n\nlibrary(\"foreign\")\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(ggpubr)\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(car)"
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html",
    "href": "posts/post-with-code/jorge_regression.html",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "",
    "text": "Step 1: Install and load the packages\n\n\n\n\npacman::p_load(\"broom\",\"ggpubr\",\"tidyverse\",\"readr\")\n\n\n\nStep 2: Load the data into R\n\n# Load the database\ndata_math <- read.csv(\"data/WMAth data.csv\")\n\n\n\nStep 3: Explore outcome variable (must be numeric)\nWe checked if the independient variables (VI) are numeric\n\nglimpse(data_math)\n\nRows: 116\nColumns: 8\n$ age         <int> 42, 23, 23, 21, 23, 22, 31, 24, 27, 23, 27, 24, 25, 26, 24…\n$ Opposites   <int> 19, 31, 29, 29, 31, 31, 37, 44, 66, 56, 40, 30, 19, 28, 46…\n$ Nspan       <int> 27, 48, 40, 46, 46, 42, 41, 46, 47, 38, 41, 32, 38, 46, 42…\n$ Colors      <int> 5, 9, 6, 9, 9, 7, 6, 5, 11, 10, 3, 7, 11, 7, 14, 8, 12, 7,…\n$ PSWQ        <int> 49, 53, 77, 74, 51, 49, 64, 28, 69, 43, 52, 53, 41, 54, 38…\n$ MARS        <int> 89, 53, 95, 109, 80, 92, 121, 47, 102, 67, 81, 108, 116, 6…\n$ Fluency     <int> 101, 151, 120, 119, 115, 112, 83, 154, 155, 104, 148, 90, …\n$ Calculation <int> 18, 33, 36, 29, 33, 23, 16, 40, 27, 32, 31, 20, 29, 35, 28…\n\n#Independent variables\n#Opposites: Verbal Working Memory\n#Nspan: Verbal Working Memory\n#Colors: Visuospatial Working Memory\n#PSWQ:The Penn State Worry Questionnaire, 16-item, 1-5 Likert  \n#MARS:The mathematical anxiety rating scale, 30-item, 0-4 Likert \n#Dependent variables\n#Fluency:Math Performance Assessment.\n#Calculation:Math Performance Assessment.\n\n\n\nStep 4: Make sure data assumptions\n\nA. Linearity\n\n# Influence of Working Memory\nplot(Calculation ~ Opposites + Nspan + Colors, data = data_math)\n\n\n\n\n\n\n\n\n\n# Influence of Math Anxiety\nplot(Fluency + Calculation ~ MARS + PSWQ, data = data_math)\n\n\n\n\n\n\n\n\n\nB. Independence of observations\nTeoricamente se entiende que las variables son independientes\n\n\n\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n#correlation\ncor(data_math$Calculation, data_math$MARS)\n\n[1] -0.4866136\n\ncor(data_math$Calculation, data_math$Opposites)\n\n[1] 0.3959613\n\ncor(data_math$Calculation, data_math$Nspan)\n\n[1] 0.3183924\n\n#variance inflation factor\nvif(m_rendimiento_lm)\n\n     MARS Opposites     Nspan \n 1.110124  1.105262  1.169471 \n\n\n\n\nC. Normality\n\n#Independent variables\n#Verbal Working Memory\nhist(data_math$Opposites) \n\n\n\nhist(data_math$Nspan)\n\n\n\n#Math Anxiety\nhist(data_math$MARS)\n\n\n\n#Independent variables\nhist(data_math$Fluency)\n\n\n\nhist(data_math$Calculation)\n\n\n\n# Se puede evaluar la normalidad por  QQplot, Kurtosis\n\n\n\n\nStep 5: Perform the linear regression analysis\n\nm_rendimiento_lm <- lm(Calculation ~ MARS + Opposites + Nspan, data = data_math)\nsummary(m_rendimiento_lm)\n\n\nCall:\nlm(formula = Calculation ~ MARS + Opposites + Nspan, data = data_math)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-14.6986  -4.7717  -0.6258   4.5865  19.0717 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 26.80750    4.04794   6.622 1.28e-09 ***\nMARS        -0.11188    0.02265  -4.940 2.75e-06 ***\nOpposites    0.19403    0.05426   3.576 0.000516 ***\nNspan        0.10409    0.07362   1.414 0.160182    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.982 on 112 degrees of freedom\nMultiple R-squared:  0.3448,    Adjusted R-squared:  0.3273 \nF-statistic: 19.65 on 3 and 112 DF,  p-value: 2.642e-10\n\n\n\n\nStep 6: Check the homocedasticity\n\npar(mfrow=c(2,2))\nplot(m_rendimiento_lm)\n\n\n\npar(mfrow=c(1,1))\n\n\n\nStep 7: Perform a graph to visualize the results\n\nprint(m_rendimiento_lm)\n\n\nCall:\nlm(formula = Calculation ~ MARS + Opposites + Nspan, data = data_math)\n\nCoefficients:\n(Intercept)         MARS    Opposites        Nspan  \n    26.8075      -0.1119       0.1940       0.1041  \n\n# Get the Intercept and coefficients as vector elements.\ncat(\"# # # # The Coefficient Values # # # \",\"\\n\")\n\n# # # # The Coefficient Values # # #  \n\na <- coef(m_rendimiento_lm)[1]\nprint(a)\n\n(Intercept) \n    26.8075 \n\nXedad <- coef(m_rendimiento_lm)[2]\nXprom <- coef(m_rendimiento_lm)[3]\nprint(Xedad)\n\n      MARS \n-0.1118795 \n\nprint(Xprom)\n\nOpposites \n0.1940296"
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html#step-1-load-the-data-into-r",
    "href": "posts/post-with-code/jorge_regression.html#step-1-load-the-data-into-r",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "Step 1: Load the data into R",
    "text": "Step 1: Load the data into R\n\n# Load the database\ndata_math <- read.csv(\"data/WMAth data.csv\")"
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html#step-3-explore-outcome-variable-must-be-numeric",
    "href": "posts/post-with-code/jorge_regression.html#step-3-explore-outcome-variable-must-be-numeric",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "Step 3: Explore outcome variable (must be numeric)",
    "text": "Step 3: Explore outcome variable (must be numeric)\nWe checked if the independient variables (VI) are numeric\n\nglimpse(data_math)\n\nRows: 116\nColumns: 8\n$ age         <int> 42, 23, 23, 21, 23, 22, 31, 24, 27, 23, 27, 24, 25, 26, 24…\n$ Opposites   <int> 19, 31, 29, 29, 31, 31, 37, 44, 66, 56, 40, 30, 19, 28, 46…\n$ Nspan       <int> 27, 48, 40, 46, 46, 42, 41, 46, 47, 38, 41, 32, 38, 46, 42…\n$ Colors      <int> 5, 9, 6, 9, 9, 7, 6, 5, 11, 10, 3, 7, 11, 7, 14, 8, 12, 7,…\n$ PSWQ        <int> 49, 53, 77, 74, 51, 49, 64, 28, 69, 43, 52, 53, 41, 54, 38…\n$ MARS        <int> 89, 53, 95, 109, 80, 92, 121, 47, 102, 67, 81, 108, 116, 6…\n$ Fluency     <int> 101, 151, 120, 119, 115, 112, 83, 154, 155, 104, 148, 90, …\n$ Calculation <int> 18, 33, 36, 29, 33, 23, 16, 40, 27, 32, 31, 20, 29, 35, 28…\n\n#Independent variables\n#Opposites: Verbal Working Memory\n#Nspan: Verbal Working Memory\n#Colors: Visuospatial Working Memory\n#PSWQ:The Penn State Worry Questionnaire, 16-item, 1-5 Likert  \n#MARS:The mathematical anxiety rating scale, 30-item, 0-4 Likert \n#Dependent variables\n#Fluency:Math Performance Assessment.\n#Calculation:Math Performance Assessment."
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html#step-4-make-sure-data-assumptions",
    "href": "posts/post-with-code/jorge_regression.html#step-4-make-sure-data-assumptions",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "Step 4: Make sure data assumptions",
    "text": "Step 4: Make sure data assumptions\n\nA. Linearity\n\n# Influence of Working Memory\nplot(Calculation ~ Opposites + Nspan + Colors, data = data_math)\n\n\n\n\n\n\n\n\n\n# Influence of Math Anxiety\nplot(Fluency + Calculation ~ MARS + PSWQ, data = data_math)\n\n\n\n\n\n\n\n\n\nB. Independence of observations\nTeoricamente se entiende que las variables son independientes\n\n\n\n\nlibrary(car)\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n#correlation\ncor(data_math$Calculation, data_math$MARS)\n\n[1] -0.4866136\n\ncor(data_math$Calculation, data_math$Opposites)\n\n[1] 0.3959613\n\ncor(data_math$Calculation, data_math$Nspan)\n\n[1] 0.3183924\n\n#variance inflation factor\nvif(m_rendimiento_lm)\n\n     MARS Opposites     Nspan \n 1.110124  1.105262  1.169471 \n\n\n\n\nC. Normality\n\n#Independent variables\n#Verbal Working Memory\nhist(data_math$Opposites) \n\n\n\nhist(data_math$Nspan)\n\n\n\n#Math Anxiety\nhist(data_math$MARS)\n\n\n\n#Independent variables\nhist(data_math$Fluency)\n\n\n\nhist(data_math$Calculation)\n\n\n\n# Se puede evaluar la normalidad por  QQplot, Kurtosis"
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html#step-3-perform-the-linear-regression-analysis",
    "href": "posts/post-with-code/jorge_regression.html#step-3-perform-the-linear-regression-analysis",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "Step 3: Perform the linear regression analysis",
    "text": "Step 3: Perform the linear regression analysis\n\nm_rendimiento_lm <- lm(Calculation ~ MARS + Opposites + Nspan, data = data_math)\nsummary(m_rendimiento_lm)\n\n\nCall:\nlm(formula = Calculation ~ MARS + Opposites + Nspan, data = data_math)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-14.6986  -4.7717  -0.6258   4.5865  19.0717 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) 26.80750    4.04794   6.622 1.28e-09 ***\nMARS        -0.11188    0.02265  -4.940 2.75e-06 ***\nOpposites    0.19403    0.05426   3.576 0.000516 ***\nNspan        0.10409    0.07362   1.414 0.160182    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.982 on 112 degrees of freedom\nMultiple R-squared:  0.3448,    Adjusted R-squared:  0.3273 \nF-statistic: 19.65 on 3 and 112 DF,  p-value: 2.642e-10"
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html#step-4-check-the-homocedasticity",
    "href": "posts/post-with-code/jorge_regression.html#step-4-check-the-homocedasticity",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "Step 4: Check the homocedasticity",
    "text": "Step 4: Check the homocedasticity\n\npar(mfrow=c(2,2))\nplot(m_rendimiento_lm)\n\n\n\npar(mfrow=c(1,1))"
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html#step-5-perform-a-graph-to-visualize-the-results",
    "href": "posts/post-with-code/jorge_regression.html#step-5-perform-a-graph-to-visualize-the-results",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "Step 5: Perform a graph to visualize the results",
    "text": "Step 5: Perform a graph to visualize the results\n\nprint(m_rendimiento_lm)\n\n\nCall:\nlm(formula = Calculation ~ MARS + Opposites + Nspan, data = data_math)\n\nCoefficients:\n(Intercept)         MARS    Opposites        Nspan  \n    26.8075      -0.1119       0.1940       0.1041  \n\n# Get the Intercept and coefficients as vector elements.\ncat(\"# # # # The Coefficient Values # # # \",\"\\n\")\n\n# # # # The Coefficient Values # # #  \n\na <- coef(m_rendimiento_lm)[1]\nprint(a)\n\n(Intercept) \n    26.8075 \n\nXedad <- coef(m_rendimiento_lm)[2]\nXprom <- coef(m_rendimiento_lm)[3]\nprint(Xedad)\n\n      MARS \n-0.1118795 \n\nprint(Xprom)\n\nOpposites \n0.1940296"
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html#step-6-check-the-homocedasticity",
    "href": "posts/post-with-code/jorge_regression.html#step-6-check-the-homocedasticity",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "Step 6: Check the homocedasticity",
    "text": "Step 6: Check the homocedasticity\n\npar(mfrow=c(2,2))\nplot(m_rendimiento_lm)\n\n\n\npar(mfrow=c(1,1))"
  },
  {
    "objectID": "posts/post-with-code/jorge_regression.html#step-7-perform-a-graph-to-visualize-the-results",
    "href": "posts/post-with-code/jorge_regression.html#step-7-perform-a-graph-to-visualize-the-results",
    "title": "Working Memory, Mathematical Anxiety",
    "section": "Step 7: Perform a graph to visualize the results",
    "text": "Step 7: Perform a graph to visualize the results\n\nprint(m_rendimiento_lm)\n\n\nCall:\nlm(formula = Calculation ~ MARS + Opposites + Nspan, data = data_math)\n\nCoefficients:\n(Intercept)         MARS    Opposites        Nspan  \n    26.8075      -0.1119       0.1940       0.1041  \n\n# Get the Intercept and coefficients as vector elements.\ncat(\"# # # # The Coefficient Values # # # \",\"\\n\")\n\n# # # # The Coefficient Values # # #  \n\na <- coef(m_rendimiento_lm)[1]\nprint(a)\n\n(Intercept) \n    26.8075 \n\nXedad <- coef(m_rendimiento_lm)[2]\nXprom <- coef(m_rendimiento_lm)[3]\nprint(Xedad)\n\n      MARS \n-0.1118795 \n\nprint(Xprom)\n\nOpposites \n0.1940296"
  },
  {
    "objectID": "posts/post-with-code/daniel_regression.html",
    "href": "posts/post-with-code/daniel_regression.html",
    "title": "Car crash and number of deathly victims: a peruvian case",
    "section": "",
    "text": "General considerations:\nDo the number of vehicles involved in a car crash have an impact in the number of deathly victims? We tested the national census of peruvian police precincts (INEI, 2017) to find out. However this analysis is, in essence, an exercise in application of the regression approach applied to publicly accessible databases.\nWe’ve divided the analysis in 6 steps, using the guide proposed by Rebecca Bevans in Linear Regression in R - A Step-by-Step Guide & Examples\n\n\nStep 1: Install and load the packages\n\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(broom)\nlibrary(ggpubr)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.1.8\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n✔ readr     2.1.4     \n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n\nlibrary(readr)\nlibrary(haven)\n\n\n\nStep 2: Load the data into R\n\n# Load the database\ndata_at <- read_sav(\"data/db_censo_comisarias.sav\")\nsummary(data_at)\n\n     ID_N              UBIGEO              CCDI             NOMBREDI        \n Length:68811       Length:68811       Length:68811       Length:68811      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n      ANIO          ID_AT             AT_N         AT_NALF         \n Min.   :2016   Min.   :  1.00   Min.   : NA     Length:68811      \n 1st Qu.:2016   1st Qu.: 10.00   1st Qu.: NA     Class :character  \n Median :2016   Median : 25.00   Median : NA     Mode  :character  \n Mean   :2016   Mean   : 29.52   Mean   :NaN                       \n 3rd Qu.:2017   3rd Qu.: 46.00   3rd Qu.: NA                       \n Max.   :2017   Max.   :200.00   Max.   : NA                       \n                                 NA's   :68811                     \n     AT_TOT           AT101         AT101_O           AT101_NRO        \n Min.   :  1.00   Min.   :1.000   Length:68811       Length:68811      \n 1st Qu.: 38.00   1st Qu.:3.000   Class :character   Class :character  \n Median : 75.00   Median :5.000   Mode  :character   Mode  :character  \n Mean   : 58.03   Mean   :3.996                                        \n 3rd Qu.: 75.00   3rd Qu.:5.000                                        \n Max.   :200.00   Max.   :6.000                                        \n                                                                       \n  AT101_ALF            AT102             AT103_D            AT103_M         \n Length:68811       Length:68811       Length:68811       Length:68811      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n   AT103_A            AT103_HOR       AT103_MIN         AT104A     \n Length:68811       Min.   : 0.00   Min.   : 0.00   Min.   :1.000  \n Class :character   1st Qu.: 9.00   1st Qu.: 5.00   1st Qu.:2.000  \n Mode  :character   Median :14.00   Median :30.00   Median :4.000  \n                    Mean   :14.96   Mean   :24.46   Mean   :3.667  \n                    3rd Qu.:18.00   3rd Qu.:40.00   3rd Qu.:4.000  \n                    Max.   :99.00   Max.   :99.00   Max.   :8.000  \n                                                                   \n   AT104A_O             AT104B        AT104B_O          AT104C_V1        \n Length:68811       Min.   :1.000   Length:68811       Length:68811      \n Class :character   1st Qu.:2.000   Class :character   Class :character  \n Mode  :character   Median :2.000   Mode  :character   Mode  :character  \n                    Mean   :2.623                                        \n                    3rd Qu.:2.000                                        \n                    Max.   :7.000                                        \n                                                                         \n  AT104C_R1          AT104C_V2          AT104C_R2         AT104D_DPTO       \n Length:68811       Length:68811       Length:68811       Length:68811      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n                                                                            \n AT104D_PROV        AT104D_DIST            AT105         AT105_O         \n Length:68811       Length:68811       Min.   : 1.00   Length:68811      \n Class :character   Class :character   1st Qu.: 4.00   Class :character  \n Mode  :character   Mode  :character   Median : 5.00   Mode  :character  \n                                       Mean   : 5.39                     \n                                       3rd Qu.: 8.00                     \n                                       Max.   :12.00                     \n                                                                         \n    AT106_1        AT106_1_CANT      AT106_2         AT106_2_CANT  \n Min.   :0.0000   Min.   :1.00    Min.   :0.00000   Min.   :1.00   \n 1st Qu.:0.0000   1st Qu.:1.00    1st Qu.:0.00000   1st Qu.:1.00   \n Median :0.0000   Median :1.00    Median :0.00000   Median :1.00   \n Mean   :0.3613   Mean   :1.19    Mean   :0.05586   Mean   :1.04   \n 3rd Qu.:1.0000   3rd Qu.:1.00    3rd Qu.:0.00000   3rd Qu.:1.00   \n Max.   :1.0000   Max.   :8.00    Max.   :1.00000   Max.   :3.00   \n                  NA's   :43947                     NA's   :64967  \n    AT106_3         AT106_3_CANT      AT106_4        AT106_4_CANT  \n Min.   :0.00000   Min.   :1.00    Min.   :0.0000   Min.   :1.00   \n 1st Qu.:0.00000   1st Qu.:1.00    1st Qu.:0.0000   1st Qu.:1.00   \n Median :0.00000   Median :1.00    Median :0.0000   Median :1.00   \n Mean   :0.08968   Mean   :1.06    Mean   :0.1725   Mean   :1.09   \n 3rd Qu.:0.00000   3rd Qu.:1.00    3rd Qu.:0.0000   3rd Qu.:1.00   \n Max.   :1.00000   Max.   :4.00    Max.   :1.0000   Max.   :6.00   \n                   NA's   :62640                    NA's   :56939  \n    AT106_5          AT106_5_CANT      AT106_6         AT106_6_CANT  \n Min.   :0.000000   Min.   :1.00    Min.   :0.00000   Min.   :1.00   \n 1st Qu.:0.000000   1st Qu.:1.00    1st Qu.:0.00000   1st Qu.:1.00   \n Median :0.000000   Median :1.00    Median :0.00000   Median :1.00   \n Mean   :0.008676   Mean   :1.03    Mean   :0.05389   Mean   :1.05   \n 3rd Qu.:0.000000   3rd Qu.:1.00    3rd Qu.:0.00000   3rd Qu.:1.00   \n Max.   :1.000000   Max.   :2.00    Max.   :1.00000   Max.   :4.00   \n                    NA's   :68214                     NA's   :65103  \n    AT106_7         AT106_7_CANT      AT106_8         AT106_8_CANT  \n Min.   :0.00000   Min.   :1.00    Min.   :0.00000   Min.   :1.00   \n 1st Qu.:0.00000   1st Qu.:1.00    1st Qu.:0.00000   1st Qu.:1.00   \n Median :0.00000   Median :1.00    Median :0.00000   Median :1.00   \n Mean   :0.02042   Mean   :1.06    Mean   :0.08654   Mean   :1.05   \n 3rd Qu.:0.00000   3rd Qu.:1.00    3rd Qu.:0.00000   3rd Qu.:1.00   \n Max.   :1.00000   Max.   :3.00    Max.   :1.00000   Max.   :4.00   \n                   NA's   :67406                     NA's   :62856  \n    AT106_9         AT106_9_CANT      AT106_10        AT106_10_CANT  \n Min.   :0.00000   Min.   :1.00    Min.   :0.000000   Min.   :1.00   \n 1st Qu.:0.00000   1st Qu.:1.00    1st Qu.:0.000000   1st Qu.:1.00   \n Median :0.00000   Median :1.00    Median :0.000000   Median :1.00   \n Mean   :0.04305   Mean   :1.11    Mean   :0.008967   Mean   :1.03   \n 3rd Qu.:0.00000   3rd Qu.:1.00    3rd Qu.:0.000000   3rd Qu.:1.00   \n Max.   :1.00000   Max.   :4.00    Max.   :1.000000   Max.   :3.00   \n                   NA's   :65849                      NA's   :68194  \n    AT106_11       AT106_11_CANT      AT106_12        AT106_12_O       \n Min.   :0.00000   Min.   :1.00    Min.   :0.00000   Length:68811      \n 1st Qu.:0.00000   1st Qu.:1.00    1st Qu.:0.00000   Class :character  \n Median :0.00000   Median :1.00    Median :0.00000   Mode  :character  \n Mean   :0.07667   Mean   :1.12    Mean   :0.00372                     \n 3rd Qu.:0.00000   3rd Qu.:1.00    3rd Qu.:0.00000                     \n Max.   :1.00000   Max.   :5.00    Max.   :1.00000                     \n                   NA's   :63535                                       \n AT106_12_CANT      AT106_13      AT106_13_CANT      AT106_14     \n Min.   :1.00    Min.   :0.0000   Min.   :1.00    Min.   :0.0000  \n 1st Qu.:1.00    1st Qu.:0.0000   1st Qu.:1.00    1st Qu.:0.0000  \n Median :1.00    Median :0.0000   Median :1.00    Median :0.0000  \n Mean   :1.01    Mean   :0.2003   Mean   :1.06    Mean   :0.1692  \n 3rd Qu.:1.00    3rd Qu.:0.0000   3rd Qu.:1.00    3rd Qu.:0.0000  \n Max.   :2.00    Max.   :1.0000   Max.   :3.00    Max.   :1.0000  \n NA's   :68555                    NA's   :55028                   \n AT106_14_CANT      AT106_15        AT106_15_CANT      AT106_16       \n Min.   : 0.00   Min.   :0.000000   Min.   :1.00    Min.   :0.000000  \n 1st Qu.: 1.00   1st Qu.:0.000000   1st Qu.:1.00    1st Qu.:0.000000  \n Median : 1.00   Median :0.000000   Median :1.00    Median :0.000000  \n Mean   : 1.12   Mean   :0.003081   Mean   :1.02    Mean   :0.008022  \n 3rd Qu.: 1.00   3rd Qu.:0.000000   3rd Qu.:1.00    3rd Qu.:0.000000  \n Max.   :10.00   Max.   :1.000000   Max.   :2.00    Max.   :1.000000  \n NA's   :57167                      NA's   :68599                     \n AT106_16_CANT      AT106_17        AT106_17_CANT      AT106_18\n Min.   :1.00    Min.   :0.000000   Min.   :1       Min.   :0  \n 1st Qu.:1.00    1st Qu.:0.000000   1st Qu.:1       1st Qu.:0  \n Median :1.00    Median :0.000000   Median :1       Median :0  \n Mean   :1.02    Mean   :0.001061   Mean   :1       Mean   :0  \n 3rd Qu.:1.00    3rd Qu.:0.000000   3rd Qu.:1       3rd Qu.:0  \n Max.   :2.00    Max.   :1.000000   Max.   :1       Max.   :0  \n NA's   :68259                      NA's   :68738              \n  AT106_18_O        AT106_18_CANT      AT107_1          AT107_2      \n Length:68811       Min.   : NA     Min.   :0.0000   Min.   :0.0000  \n Class :character   1st Qu.: NA     1st Qu.:0.0000   1st Qu.:0.0000  \n Mode  :character   Median : NA     Median :0.0000   Median :1.0000  \n                    Mean   :NaN     Mean   :0.2991   Mean   :0.5817  \n                    3rd Qu.: NA     3rd Qu.:1.0000   3rd Qu.:1.0000  \n                    Max.   : NA     Max.   :1.0000   Max.   :1.0000  \n                    NA's   :68811                                    \n    AT107_3           AT108          AT108_1         AT108_2      \n Min.   :0.0000   Min.   :1.000   Min.   : 1.00   Min.   : 0.000  \n 1st Qu.:0.0000   1st Qu.:2.000   1st Qu.: 1.00   1st Qu.: 1.000  \n Median :0.0000   Median :2.000   Median : 1.00   Median : 1.000  \n Mean   :0.2245   Mean   :2.332   Mean   : 1.28   Mean   : 1.609  \n 3rd Qu.:0.0000   3rd Qu.:3.000   3rd Qu.: 1.00   3rd Qu.: 2.000  \n Max.   :1.0000   Max.   :3.000   Max.   :24.00   Max.   :72.000  \n                                  NA's   :66355   NA's   :25305   \n    AT108_3          AT109_1          AT109_2           AT109_3        \n Min.   : 0.000   Min.   :0.0000   Min.   :0.00000   Min.   :0.000000  \n 1st Qu.: 1.000   1st Qu.:0.0000   1st Qu.:0.00000   1st Qu.:0.000000  \n Median : 1.000   Median :0.0000   Median :0.00000   Median :0.000000  \n Mean   : 1.278   Mean   :0.2434   Mean   :0.01888   Mean   :0.006336  \n 3rd Qu.: 2.000   3rd Qu.:0.0000   3rd Qu.:0.00000   3rd Qu.:0.000000  \n Max.   :66.000   Max.   :1.0000   Max.   :1.00000   Max.   :1.000000  \n                                                                       \n    AT109_4            AT109_5           AT109_6          AT109_7       \n Min.   :0.000000   Min.   :0.00000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.000000   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.000000   Median :0.00000   Median :0.0000   Median :0.00000  \n Mean   :0.006903   Mean   :0.08513   Mean   :0.2281   Mean   :0.03225  \n 3rd Qu.:0.000000   3rd Qu.:0.00000   3rd Qu.:0.0000   3rd Qu.:0.00000  \n Max.   :1.000000   Max.   :1.00000   Max.   :1.0000   Max.   :1.00000  \n                                                                        \n    AT109_8           AT109_9           AT109_10           AT109_11      \n Min.   :0.00000   Min.   :0.00000   Min.   :0.000000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.00000   1st Qu.:0.000000   1st Qu.:0.00000  \n Median :0.00000   Median :0.00000   Median :0.000000   Median :0.00000  \n Mean   :0.03119   Mean   :0.05479   Mean   :0.007106   Mean   :0.02375  \n 3rd Qu.:0.00000   3rd Qu.:0.00000   3rd Qu.:0.000000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.00000   Max.   :1.000000   Max.   :1.00000  \n                                                                         \n    AT109_12           AT109_13           AT109_14           AT109_15     \n Min.   :0.000000   Min.   :0.000000   Min.   :0.000000   Min.   :0.0000  \n 1st Qu.:0.000000   1st Qu.:0.000000   1st Qu.:0.000000   1st Qu.:0.0000  \n Median :0.000000   Median :0.000000   Median :0.000000   Median :0.0000  \n Mean   :0.006336   Mean   :0.008371   Mean   :0.001119   Mean   :0.1537  \n 3rd Qu.:0.000000   3rd Qu.:0.000000   3rd Qu.:0.000000   3rd Qu.:0.0000  \n Max.   :1.000000   Max.   :1.000000   Max.   :1.000000   Max.   :1.0000  \n                                                                          \n    AT109_16          AT109_17           AT109_18         AT109_19      \n Min.   :0.00000   Min.   :0.000000   Min.   :0.0000   Min.   :0.00000  \n 1st Qu.:0.00000   1st Qu.:0.000000   1st Qu.:0.0000   1st Qu.:0.00000  \n Median :0.00000   Median :0.000000   Median :0.0000   Median :0.00000  \n Mean   :0.00981   Mean   :0.001177   Mean   :0.2867   Mean   :0.02758  \n 3rd Qu.:0.00000   3rd Qu.:0.000000   3rd Qu.:1.0000   3rd Qu.:0.00000  \n Max.   :1.00000   Max.   :1.000000   Max.   :1.0000   Max.   :1.00000  \n                                                                        \n  AT109_19_O         Factor_2016      Factor_2017   \n Length:68811       Min.   : 1.000   Min.   : 1.00  \n Class :character   1st Qu.: 1.000   1st Qu.: 1.00  \n Mode  :character   Median : 1.293   Median : 1.00  \n                    Mean   : 2.912   Mean   : 2.00  \n                    3rd Qu.: 3.080   3rd Qu.: 1.95  \n                    Max.   :19.760   Max.   :12.05  \n                    NA's   :28751    NA's   :40060  \n\n\n\n\nStep 3: Explore outcome variable (must be numeric)\nWe checked if the independent variable automoviles involucrados (VI - AT_106_1) is numeric. A general look at the database shows that this number represents only the value for cars of sedan or hatchback models, while other automobiles such as trucks, station wagons, buses or vans are excluded from this count.\nIt can be said that the variable could be considered as a categoric variable. While it has a numeric linear value, the max output is limited to 5. Added to this the output for any value of vehicles belongs to \\(N\\) , as you can’t have half a vehicle involved in a car accident, which furthers the argument for a categorical analysis. Linear Regression is possible with one independent categoric variable, but has special considerations in the interpretation of its data.\nFor practice purposes we’ll consider it as a numeric variable, as the analysis with categoric variables omits many of the interpretations in a numeric variable.\n\nheridos <- data_at$AT108_2\nvehiculos <- data_at$AT106_1_CANT\nglimpse(heridos) #Numeric\n\n num [1:68811] NA 2 NA 1 1 1 0 NA 1 1 ...\n - attr(*, \"label\")= chr \"NÚMERO DE HERIDOS\"\n - attr(*, \"format.spss\")= chr \"F11.0\"\n - attr(*, \"display_width\")= int 11\n\nglimpse(vehiculos) #Numeric\n\n num [1:68811] 1 1 NA NA NA 1 1 NA NA NA ...\n - attr(*, \"label\")= chr \"VEHÍCULO MAYOR  AUTOMÓVIL - CANTIDAD\"\n - attr(*, \"format.spss\")= chr \"F11.0\"\n - attr(*, \"display_width\")= int 11\n\n\n\n\nStep 4: Make sure data assumptions\n\nA. Linearity\nWhen checking for linearity we can see that the points are not scattered in a linear distribution, they form columns for each whole value. They miss the mark in forming some sort of bell curve and most of the cases had only 1 automobile involved.\n\nplot(heridos ~ vehiculos, data = data_at)\n\n\n\n\n\n\nB. Independence of observations\nTheoretically, we expect each variable to be independent\n\n\nC. Normality\nWhen checking for normality, the histogram is not bell shaped, which states a tendency of values in the lower numbers of the independent variable. Most of the cases had 1 or 2 automovile vehicles involved.\n\nhist(vehiculos)\n\n\n\n# Se puede evaluar la normalidad por  QQplot, Kurtosis\n\n\n\n\nStep 5: Perform the linear regression analysis\nIn the analysis we see that the p value is favorable to us, as it is low enough to make this a good model. It appears to be a significant positive relationship between vehicles and people hurt in car accidents, with a 0,44 increase in people hurt for every unit of vehicles involved.\nHowever, if we treat the variables as categorical ones, we can omit the linearity analysis and insist on this relation without trouble.\n\ndata_at_lm <- lm(heridos ~ vehiculos, data = data_at)\nsummary(data_at_lm)\n\n\nCall:\nlm(formula = heridos ~ vehiculos, data = data_at)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.3146 -0.5449 -0.5449  0.4551 27.4551 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.10247    0.03667   30.06   <2e-16 ***\nvehiculos    0.44243    0.03089   14.32   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.307 on 13116 degrees of freedom\n  (55693 observations deleted due to missingness)\nMultiple R-squared:  0.0154,    Adjusted R-squared:  0.01533 \nF-statistic: 205.2 on 1 and 13116 DF,  p-value: < 2.2e-16\n\n\n\n\nStep 6: Check the homocedasticity\nResiduals show bias, as they are distributed between the two first values. If we consider the “vehicles” variable as categorical then we can also omit this test\n\npar(mfrow=c(2,2))\nplot(data_at_lm)\n\n\n\npar(mfrow=c(1,1))\n\n\n\nStep 7: Perform a graph to visualize the results\nWith the previous steps done we can graph the linear model an see that the number of vehicles involved has (eventhough small) a relation to the number of peopler hurt in the accident\n\ngraph <- ggplot(data_at, aes(x=vehiculos, y=heridos)) + geom_point()\ngraph <- graph + geom_smooth(method='lm', col='blue')\ngraph <- graph + stat_regline_equation(label.x = 3, label.y = 7)\ngraph\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 55693 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 55693 rows containing non-finite values\n(`stat_regline_equation()`).\n\n\nWarning: Removed 55693 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\nrelation <- lm(vehiculos~heridos)\n# give the chart a name\npng(file = \"linearregression.png\")\n# Plot\nplot(vehiculos,heridos, col = \"blue\", main = \"Regresión de vehículos y heridos en choques de autos\",\nabline(lm(vehiculos~heridos)), cex = 1.3, pch = 16, xlab = \"vehiculos\", ylab = \"heridos\")\n\n\n\nStep 8: Report and interpret your results\nWe can interpret of this analysis that the number automovile vehicles invovled in car accidents have a relation with the number of wounded people. In our next analysis we will sum the number of different types of vehicles involved, so we can get a complete picture of the relation between vehicles involved and total number of wounde people.\nWe will also try to create an html site where you can select the type of vehicle you wish to add in the analysis"
  },
  {
    "objectID": "posts/post-with-code/elias_regression.html",
    "href": "posts/post-with-code/elias_regression.html",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "",
    "text": "Original Research: Reactance and perceived disease severity as determinants of COVID-19 vaccination intention: An application of the theory of planned behavior\nAuthors: Dariusz Drążkowski, Radosław Trepanowski, Adam Mickiewicz\nYear: 2021\nSample: 551 Polish participants\nDOI: https://doi.org/10.1080/13548506.2021.2014060"
  },
  {
    "objectID": "posts/post-with-code/elias_regression.html#multiple-regression-analysis-step-by-step",
    "href": "posts/post-with-code/elias_regression.html#multiple-regression-analysis-step-by-step",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "Multiple Regression Analysis: Step by step",
    "text": "Multiple Regression Analysis: Step by step\nProblem: What are the determinants of COVID-19 vaccination intention?\nObjective: To identify the determinants of COVID-19 vaccination through an application of the Theory of Planned Behavior.\nHypothesis: H1: Control beliefs have a direct impact on COVID-19 vaccination intention H2: Utility beliefs have a direct impact on COVID-19 vaccination intention H3: Social norm beliefs have a direct impact on COVID-19 vaccination intention\nSteps to prove the hypothesis\nA. Model Evaluation\n\nRegression coeficients and r-square\nInterpretation\n\nB. Regression Model Assumtions\n\nLineality between IVs and Dv\nIndependence of observations: The observation from our model are independent.\nHomoscedasticity: The errors from our model have equal variance.\nNormality of Errors: The errors from our model are normally distributed.\nMulticollinality: evaluate if the IVs are redundant.\n\n\nLoad the packages\n\nlibrary(\"foreign\")\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(broom)\nlibrary(ggpubr)\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(car)"
  },
  {
    "objectID": "posts/post-with-code/elias_regression.html#a.-model-evaluation",
    "href": "posts/post-with-code/elias_regression.html#a.-model-evaluation",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "A. Model Evaluation",
    "text": "A. Model Evaluation\n\nA1. Regression coeficients and r-square\nLoad the database\n\nMydata=read.spss(\"data/COVID_data.sav\",to.data.frame=T,use.value.labels=FALSE)\nsummary(Mydata$SE_Total)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   3.00   12.00   15.00   15.42   18.00   21.00 \n\n\nPerform the linear regression analysis\n\nIntention_lm <- lm(IN_Total ~ SN_Total + BC_Total + AT_Total, data = Mydata)\nsummary(Intention_lm)\n\n\nCall:\nlm(formula = IN_Total ~ SN_Total + BC_Total + AT_Total, data = Mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.4622  -1.2412   0.1199   1.3464  11.0907 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -1.71571    0.36855  -4.655 4.07e-06 ***\nSN_Total     0.36218    0.03976   9.109  < 2e-16 ***\nBC_Total     0.29052    0.03483   8.341 6.00e-16 ***\nAT_Total     0.45369    0.03504  12.946  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.457 on 547 degrees of freedom\nMultiple R-squared:  0.7865,    Adjusted R-squared:  0.7853 \nF-statistic: 671.5 on 3 and 547 DF,  p-value: < 2.2e-16\n\n\n\n\nA2. Interpretation\nBs ajusted:\nFor each point obtained in the scale of subjective norms, the intenton to COVID-19 vaccination intention will increase 0.36 points. Also, subjective norms had a direct effect on COVID-19 vaccination intention it was statistically significant.\nFor each point obtained in the scale of Behavioral Control, the intenton to COVID-19 vaccination intention will increase 0.29 points. Also, Behavioral Control had a direct effect on COVID-19 vaccination intention and it was statistically significant.\nFor each point obtained in the scale of Attitude Toward Covid-19 vaccination, the intenton to COVID-19 vaccination intention will increase 0.45 points. Also, Attitude Toward Covid-19 vaccination had a direct effect on COVID-19 vaccination intention and statistical significance.\nThe model with these three determinants explain 78% of variance of COVID-19 vaccination intention."
  },
  {
    "objectID": "posts/post-with-code/elias_regression.html#b.-regression-model-assumtions",
    "href": "posts/post-with-code/elias_regression.html#b.-regression-model-assumtions",
    "title": "Determinants of COVID-19 vaccination intention",
    "section": "B. Regression Model Assumtions",
    "text": "B. Regression Model Assumtions\n\nB1. Lineality between IVs and Dv\n\nplot(IN_Total ~ SN_Total, data = Mydata)\n\n\n\nplot(IN_Total ~ BC_Total, data = Mydata)\n\n\n\nplot(IN_Total ~ AT_Total, data = Mydata)\n\n\n\n\n\n\nB2. Independence of observations\nThe observation from our model are independent.\nThis was fulfilled when each observation was made by one participant.\n\n\nB3. Homocedasticity\nThe errors from our model have equal variance.\n\npar(mfrow=c(2,2))\nplot(Intention_lm)\n\n\n\npar(mfrow=c(1,1))\n\n\n\nB4. Normality of Errors\nThe errors from our model are normally distributed.\n\npar(mfrow=c(2,2))\nplot(Intention_lm)\n\n\n\npar(mfrow=c(1,1))\n\n\n\nB5. Multicollinality: evaluate if the IVs are redundant.\n\nvif(Intention_lm)\n\nSN_Total BC_Total AT_Total \n2.984366 1.899331 2.991759"
  }
]